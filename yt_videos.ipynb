{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from selenium.webdriver import Chrome\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from concurrent import futures\n",
    "\n",
    "ARTIST_DATASET_PATH = 'datasets/artists.csv'\n",
    "VIDEOS_DATASET_PATH = 'datasets/videos.csv'\n",
    "\n",
    "ID = 'id'\n",
    "NAME = 'name'\n",
    "YOUTUBE = 'youtube_url'\n",
    "SPOTIFY = 'spotify_uri'\n",
    "\n",
    "CHANNEL = 'channel'\n",
    "TITLE = 'title'\n",
    "URL = 'url'\n",
    "\n",
    "VIDEOS_URL = '%s/videos'\n",
    "VIDEO_SELECTOR = '#content.ytd-rich-item-renderer'\n",
    "ANCHOR_SELECTOR = 'a#thumbnail'\n",
    "TITLE_SELECTOR = '#video-title'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_yt_videos(url, options=None):\n",
    "    video_urls = []\n",
    "    video_titles = []\n",
    "    with Chrome(options=options) as driver:\n",
    "        wait = WebDriverWait(driver,3)\n",
    "        driver.get(VIDEOS_URL % url)\n",
    "\n",
    "        cookies_reject = driver.find_element(By.XPATH, \"//button[@aria-label='Reject all']\")\n",
    "        cookies_reject.click()\n",
    "        time.sleep(5)\n",
    "\n",
    "        last_videos_len = None\n",
    "        while len(video_urls) != last_videos_len:\n",
    "            last_videos_len = len(video_urls)\n",
    "            wait.until(EC.presence_of_element_located((By.TAG_NAME, 'body'))).send_keys(Keys.END)\n",
    "\n",
    "            for video in driver.find_elements(By.CSS_SELECTOR, VIDEO_SELECTOR):\n",
    "                anchor_tag = video.find_element(By.CSS_SELECTOR, ANCHOR_SELECTOR)\n",
    "                link = anchor_tag.get_attribute('href')\n",
    "                if link not in video_urls:\n",
    "                    video_urls.append(link)\n",
    "\n",
    "                    title = video.find_element(By.CSS_SELECTOR, TITLE_SELECTOR).text\n",
    "                    video_titles.append(title)\n",
    "\n",
    "            time.sleep(1)\n",
    "\n",
    "    return list(zip(video_urls, video_titles))\n",
    "\n",
    "\n",
    "def get_all_yt_videos(yt_channels, videos_df, n=None, timeout=20, verbose=False):\n",
    "    options = Options()\n",
    "    options.add_argument('--headless=new')\n",
    "    options.add_argument('--window-size=2560,1440')\n",
    "    with futures.ThreadPoolExecutor() as executor:\n",
    "        all_future_videos = []\n",
    "        for url in yt_channels:\n",
    "            all_future_videos.append((\n",
    "                url,\n",
    "                executor.submit(get_yt_videos, url, options)\n",
    "                ))\n",
    "            if len(all_future_videos) == n:\n",
    "                break\n",
    "\n",
    "        for (channel_url, future_videos) in all_future_videos:\n",
    "            try:        \n",
    "                videos = future_videos.result(timeout=timeout)\n",
    "\n",
    "                rows = []\n",
    "                for (video_url, video_title) in videos:\n",
    "                    if video_url not in videos_df[URL].values:\n",
    "                        rows.append({\n",
    "                            CHANNEL: channel_url,\n",
    "                            TITLE: video_title,\n",
    "                            URL: video_url\n",
    "                        })\n",
    "                \n",
    "                new_videos_df = pd.DataFrame(rows, columns=[CHANNEL, URL, TITLE])\n",
    "                videos_df = pd.concat([videos_df, new_videos_df], ignore_index=True)\n",
    "                \n",
    "                if verbose:\n",
    "                    print(f'found {len(rows)} videos for {channel_url}')\n",
    "                videos_df.to_csv(VIDEOS_DATASET_PATH, index=ID)\n",
    "            except Exception as exc:\n",
    "                if verbose:\n",
    "                    print(f'{channel_url} generated an exception')\n",
    "                    print(exc)\n",
    "    return videos_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>channel</th>\n",
       "      <th>url</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [channel, url, title]\n",
       "Index: []"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "try:\n",
    "    videos = pd.read_csv(VIDEOS_DATASET_PATH, index_col=ID)\n",
    "except FileNotFoundError:\n",
    "    videos = pd.DataFrame(columns=[ID, CHANNEL, URL, TITLE])\n",
    "    videos.set_index(ID, inplace=True)\n",
    "    videos.to_csv(VIDEOS_DATASET_PATH, index=ID)\n",
    "\n",
    "artists = pd.read_csv(ARTIST_DATASET_PATH)\n",
    "videos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found 171 videos for https://www.youtube.com/@DrakeOfficial\n",
      "found 123 videos for https://www.youtube.com/@BadBunnyPR\n",
      "found 293 videos for https://www.youtube.com/@EdSheeran\n",
      "found 342 videos for https://www.youtube.com/@TheWeeknd\n"
     ]
    }
   ],
   "source": [
    "yt_channels = artists[YOUTUBE].dropna().values[:5]\n",
    "videos_df = get_all_yt_videos(yt_channels, videos, verbose=True, timeout=120)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
